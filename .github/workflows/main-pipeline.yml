name: Main Pipeline

on:
  push:
    branches:
      - main
    tags:
      - 'v*'
  workflow_dispatch:
    inputs:
      triggered_by:
        description: 'Workflow that triggered this run'
        required: false
        default: 'manual'

# Improve concurrency handling to avoid cancelling important runs
concurrency:
  group: main-pipeline-${{ github.sha }}
  cancel-in-progress: false

# Define reusable variables
env:
  BUILD_ARTIFACT_NAME: build-artifacts-${{ github.run_id }}
  PACKAGES_ARTIFACT_NAME: package-builds-${{ github.run_id }}
  TRIGGERING_WORKFLOW: ${{ github.event.inputs.triggered_by || 'direct' }}
  
# Note: This workflow handles GitHub Pages deployment directly.
# The separate deploy-pages.yml workflow should be disabled or deleted.
permissions:
  contents: write
  packages: write
  pull-requests: write
  statuses: write
  id-token: write
  actions: write
  issues: write

jobs:
  # Capture information about what triggered this workflow
  capture-trigger-info:
    name: Capture Trigger Info
    runs-on: ubuntu-latest
    outputs:
      trigger_info: ${{ steps.set-trigger-info.outputs.trigger_info }}
      trigger_workflow: ${{ steps.set-trigger-info.outputs.trigger_workflow }}
      trigger_commit: ${{ steps.set-trigger-info.outputs.trigger_commit }}
      trigger_actor: ${{ steps.set-trigger-info.outputs.trigger_actor }}
      trigger_detail: ${{ steps.set-trigger-info.outputs.trigger_detail }}
      source_branch: ${{ steps.set-trigger-info.outputs.source_branch }}
      is_merge_pr: ${{ steps.check-merge-pr.outputs.is_merge_pr }}
      pr_number: ${{ steps.check-merge-pr.outputs.pr_number }}
      source_branch_name: ${{ steps.check-merge-pr.outputs.source_branch_name }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set trigger information
        id: set-trigger-info
        run: |
          # Determine what triggered this workflow
          if [ "${{ github.event_name }}" == "workflow_dispatch" ] && [ "${{ github.event.inputs.triggered_by }}" != "" ]; then
            # Triggered by another workflow
            echo "trigger_workflow=${{ github.event.inputs.triggered_by }}" >> $GITHUB_OUTPUT
            echo "trigger_info=Triggered by ${{ github.event.inputs.triggered_by }} workflow" >> $GITHUB_OUTPUT
            
            # Extract source branch or command from commit message
            LAST_COMMIT=$(git log -1 --pretty=%B)
            
            if [[ "${{ github.event.inputs.triggered_by }}" == "push-create-pr" ]]; then
              # Extract PR number and branch from commit message
              PR_NUM=$(echo "$LAST_COMMIT" | grep -oP "Merge PR #\K\d+")
              SOURCE_BRANCH=$(echo "$LAST_COMMIT" | grep -oP "from \K[^ \n]+")
              echo "trigger_detail=PR #${PR_NUM:-unknown} from branch ${SOURCE_BRANCH:-unknown}" >> $GITHUB_OUTPUT
              echo "source_branch=${SOURCE_BRANCH:-unknown}" >> $GITHUB_OUTPUT
            else
              echo "trigger_detail=From ${{ github.event.inputs.triggered_by }}" >> $GITHUB_OUTPUT
              echo "source_branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT
            fi
            
          elif [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            # Manual trigger
            echo "trigger_workflow=manual" >> $GITHUB_OUTPUT
            echo "trigger_info=Manually triggered by ${{ github.actor }}" >> $GITHUB_OUTPUT
            echo "trigger_detail=Manual workflow dispatch" >> $GITHUB_OUTPUT
            echo "source_branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT
            
          elif [ "${{ github.event_name }}" == "push" ] && [[ "${{ github.ref }}" == refs/tags/* ]]; then
            # Tag push
            echo "trigger_workflow=tag_push" >> $GITHUB_OUTPUT
            echo "trigger_info=Triggered by tag push to ${{ github.ref_name }}" >> $GITHUB_OUTPUT
            echo "trigger_detail=Tag: ${{ github.ref_name }}" >> $GITHUB_OUTPUT
            echo "source_branch=tag:${{ github.ref_name }}" >> $GITHUB_OUTPUT
            
          else
            # Direct push to main
            echo "trigger_workflow=direct_push" >> $GITHUB_OUTPUT
            echo "trigger_info=Triggered by push to ${{ github.ref_name }}" >> $GITHUB_OUTPUT
            
            # Extract commit message details
            COMMIT_MSG=$(git log -1 --pretty=%B)
            COMMIT_TITLE=$(echo "$COMMIT_MSG" | head -n 1)
            echo "trigger_detail=Direct commit: ${COMMIT_TITLE}" >> $GITHUB_OUTPUT
            echo "source_branch=${{ github.ref_name }}" >> $GITHUB_OUTPUT
          fi
          
          # Set commit and actor info
          echo "trigger_commit=${{ github.sha }}" >> $GITHUB_OUTPUT
          echo "trigger_actor=${{ github.actor }}" >> $GITHUB_OUTPUT
          
          # Print debug info
          echo "Workflow triggered by: ${{ github.event_name }}"
          echo "Actor: ${{ github.actor }}"
          echo "Ref: ${{ github.ref }}"
          echo "SHA: ${{ github.sha }}"
      
      - name: Check if this is a PR merge
        id: check-merge-pr
        run: |
          # Get the last commit message
          COMMIT_MSG=$(git log -1 --pretty=%B)
          
          # Check if this is a merge commit from a PR
          if [[ "$COMMIT_MSG" =~ ^Merge\ pull\ request\ #([0-9]+)\ from\ ([^ ]+) ]]; then
            PR_NUM="${BASH_REMATCH[1]}"
            SOURCE_BRANCH="${BASH_REMATCH[2]}"
            echo "This is a PR merge: PR #$PR_NUM from $SOURCE_BRANCH"
            echo "is_merge_pr=true" >> $GITHUB_OUTPUT
            echo "pr_number=$PR_NUM" >> $GITHUB_OUTPUT
            echo "source_branch_name=$SOURCE_BRANCH" >> $GITHUB_OUTPUT
            
            # Get all commits that were in this PR
            echo "Fetching PR commits..."
            MERGE_BASE=$(git merge-base HEAD^ HEAD)
            echo "Merge base: $MERGE_BASE"
            
            # Print all commits in this merge for debugging
            echo "Commits in this PR merge:"
            git log --pretty=format:"%h %s" $MERGE_BASE..HEAD^ | cat
          else
            echo "Not a PR merge"
            echo "is_merge_pr=false" >> $GITHUB_OUTPUT
          fi

  build:
    name: Build
    needs: capture-trigger-info
    runs-on: ubuntu-latest
    outputs:
      build_artifact_name: ${{ env.BUILD_ARTIFACT_NAME }}
      trigger_info: ${{ needs.capture-trigger-info.outputs.trigger_info }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
          
      - name: Debug environment
        run: |
          echo "Debugging environment before build..."
          echo "Node version: $(node -v)"
          echo "NPM version: $(npm -v)"
          command -v pnpm && echo "pnpm version: $(pnpm -v)" || echo "pnpm not found"
          echo "Current directory: $(pwd)"
          echo "Directory contents:"
          ls -la
          echo "Checking for package.json:"
          cat package.json | grep -E 'name|scripts|build'
          echo "Installing dependencies explicitly:"
          npm install -g pnpm
          pnpm install
          echo "Environment debug complete"
          
      # Update .npmrc files to not require NODE_AUTH_TOKEN
      - name: Update .npmrc files
        run: |
          chmod +x .github/scripts/maintenance/update-npmrc.js
          node .github/scripts/maintenance/update-npmrc.js
          
      - name: Build packages
        uses: ./.github/actions/build-and-test
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          build-command: 'pnpm run build'
          test-command: 'echo "Tests will run in separate job"'
          artifact-name: ${{ env.BUILD_ARTIFACT_NAME }}
        
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BUILD_ARTIFACT_NAME }}
          path: packages
          if-no-files-found: error
          
      - name: Validate build artifacts
        run: |
          echo "Validating build artifacts..."
          # Check for dist directories
          DIST_DIRS=$(find packages -name "dist" -type d | wc -l)
          if [ "$DIST_DIRS" -eq 0 ]; then
            echo "::error::No dist directories found in packages!"
            exit 1
          fi
          echo "Found $DIST_DIRS dist directories"
          
          # List all dist directories to verify they exist and contain files
          find packages -name "dist" -type d -exec ls -la {} \;
          
          # Count files to ensure we have artifacts
          FILE_COUNT=$(find packages -name "dist" -type d -exec find {} -type f \; | wc -l)
          echo "Found $FILE_COUNT files in artifact directories"
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "::error::No build artifacts found in packages/dist directories!"
            exit 1
          fi
          
          echo "✅ Artifact validation successful - $FILE_COUNT files in $DIST_DIRS directories"
          
      - name: Display trigger info
        run: echo "This build was ${{ needs.capture-trigger-info.outputs.trigger_info }}"

  test:
    name: Test
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
          
      # Download build artifacts explicitly first
      - name: Download build artifacts
        id: download-artifacts
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.build.outputs.build_artifact_name }}
          path: packages
        env:
          GH_TOKEN: ${{ secrets.PACKAGE_TOKEN }}
          
      # Validate that artifacts were successfully downloaded
      - name: Validate downloaded artifacts
        run: |
          echo "Validating downloaded artifacts..."
          # Check that artifacts were downloaded
          DIST_DIRS=$(find packages -name "dist" -type d | wc -l)
          if [ "$DIST_DIRS" -eq 0 ]; then
            echo "::error::No dist directories found in downloaded artifacts!"
            exit 1
          fi
          
          # Count files to ensure we have artifacts
          FILE_COUNT=$(find packages -name "dist" -type d -exec find {} -type f \; | wc -l)
          echo "Found $FILE_COUNT files in $DIST_DIRS artifact directories"
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "::error::Downloaded artifacts contain no files!"
            exit 1
          fi
          
          echo "✅ Downloaded artifacts validation successful"
          
      # Replace workflow call with direct use of the action
      - name: Test packages
        uses: ./.github/actions/test-packages
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          artifact-name: ${{ needs.build.outputs.build_artifact_name }}

  version-and-tag:
    name: Version and Tag Packages
    needs: [test, build, capture-trigger-info]
    if: success() && (github.event_name == 'push' || github.event_name == 'workflow_dispatch')
    runs-on: ubuntu-latest
    permissions:
      contents: write
      packages: write
    outputs:
      packages_updated: ${{ steps.bump-versions.outputs.packages_updated }}
      packages_tagged: ${{ steps.create-tags.outputs.packages_tagged }}
      error-message: ${{ steps.create-tags.outputs.error-message }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.VERSION_TOKEN }}
          
      # Download build artifacts
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.build.outputs.build_artifact_name }}
          path: packages
        env:
          GH_TOKEN: ${{ secrets.VERSION_TOKEN }}
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 'lts/*'
          registry-url: 'https://npm.pkg.github.com'
          
      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: '8.15.4'
          
      - name: Install dependencies
        run: pnpm install
        
      # Special handling for PR merges to examine all commits
      - name: Prepare for PR merge versioning
        if: needs.capture-trigger-info.outputs.is_merge_pr == 'true'
        run: |
          echo "This is a PR merge: #${{ needs.capture-trigger-info.outputs.pr_number }} from ${{ needs.capture-trigger-info.outputs.source_branch_name }}"
          
          # Find the merge base to get all commits in the PR
          MERGE_BASE=$(git merge-base HEAD^ HEAD)
          echo "Merge base: $MERGE_BASE"
          
          # Get all commits in the PR and write to a file for debugging
          git log --pretty=format:"%h %s" $MERGE_BASE..HEAD^ > pr_commits.txt
          echo "PR commits:"
          cat pr_commits.txt
          
          # Store the merge base for versioning script to use
          echo "MERGE_BASE=$MERGE_BASE" >> $GITHUB_ENV
          
      # Modify the test-version-merge.js script to accept a dry-run parameter
      - name: Update version script to accept parameters
        run: |
          # Create a wrapper script that takes parameters including dry-run
          cat << 'EOF' > scripts/version-runner.js
          #!/usr/bin/env node

          /**
           * Version Runner Script
           * 
           * This script runs the version calculation logic, either in dry-run mode
           * or applied mode to actually update package versions.
           */

          const { execSync } = require('child_process');
          const path = require('path');
          const fs = require('fs');
          const args = process.argv.slice(2);

          // Process command line arguments
          const params = {
            dryRun: true, // Default to dry run
            outputJson: false,
            mergeBase: null
          };

          for (const arg of args) {
            if (arg === '--apply' || arg === '--no-dry-run') {
              params.dryRun = false;
            } else if (arg === '--output-json') {
              params.outputJson = true;
            } else if (arg.startsWith('--merge-base=')) {
              params.mergeBase = arg.split('=')[1];
            }
          }

          // If MERGE_BASE env var is set, use it
          if (process.env.MERGE_BASE && !params.mergeBase) {
            params.mergeBase = process.env.MERGE_BASE;
          }

          console.log(`Running with parameters: ${JSON.stringify(params)}`);

          // Import the test-version-merge.js logic but make it callable with params
          const versionMergePath = path.join(__dirname, 'test-version-merge.js');
          const versionMergeContent = fs.readFileSync(versionMergePath, 'utf8');

          // Extract the core functions from test-version-merge.js
          const utilsPath = path.join(__dirname, 'version-utils.js');
          const { BUMP_TYPES, incrementVersion, extractScope, extractCommitType, determineBumpType } = require(utilsPath);

          // Identify the package paths to version
          const versionPackagesPath = path.join(__dirname, 'version-packages.js');
          const versionPackagesContent = fs.readFileSync(versionPackagesPath, 'utf8');

          // Extract configuration from version-packages.js
          let PACKAGES, EXCLUDED_SCOPES;
          const packageMatch = versionPackagesContent.match(/const PACKAGES = \[([\s\S]*?)\];/);
          if (packageMatch) {
            PACKAGES = eval(`[${packageMatch[1]}]`);
          } else {
            PACKAGES = [
              'packages/blorkpack',
              'packages/blorktools',
              'packages/blorkboard',
              'apps/portfolio'
            ];
          }

          const excludedMatch = versionPackagesContent.match(/const EXCLUDED_SCOPES = \[([\s\S]*?)\];/);
          if (excludedMatch) {
            EXCLUDED_SCOPES = eval(`[${excludedMatch[1]}]`);
          } else {
            EXCLUDED_SCOPES = ['pipeline', 'ci', 'workflows', 'github', 'actions'];
          }

          // Define ANSI color codes for console output
          const colors = {
            reset: '\x1b[0m',
            bright: '\x1b[1m',
            green: '\x1b[32m',
            yellow: '\x1b[33m',
            blue: '\x1b[34m',
            magenta: '\x1b[35m',
            cyan: '\x1b[36m',
            red: '\x1b[31m',
          };

          /**
           * Gets the name of the current branch
           * @returns {string} Current branch name
           */
          function getCurrentBranch() {
            try {
              return execSync('git rev-parse --abbrev-ref HEAD').toString().trim();
            } catch (error) {
              console.error(`${colors.red}Error getting current branch:${colors.reset}`, error.message);
              process.exit(1);
            }
          }

          /**
           * Gets the merge base between the current branch and main
           * @param {string} currentBranch - Name of the current branch
           * @returns {string} Merge base commit SHA
           */
          function getMergeBase(currentBranch) {
            try {
              return execSync(`git merge-base main ${currentBranch}`).toString().trim();
            } catch (error) {
              console.error(`${colors.red}Error finding merge base:${colors.reset}`, error.message);
              console.error(`${colors.yellow}Make sure 'main' branch exists and you have the latest version.${colors.reset}`);
              process.exit(1);
            }
          }

          /**
           * Get detailed commit info
           * @param {string} commitHash Commit hash
           * @returns {Object} Commit details including hash, message, type, bumpType
           */
          function getCommitDetails(commitHash) {
            const shortHash = commitHash.slice(0, 7);
            const message = execSync(`git log --format=%s -n 1 ${commitHash}`).toString().trim();
            const type = extractCommitType(message) || 'unknown';
            // Determine what bump type this individual commit would contribute
            const bumpType = determineBumpType(message);
            
            return {
              hash: shortHash,
              message,
              type,
              bumpType // Track the individual bump type for this commit
            };
          }

          /**
           * Get all commits since base commit and determine which packages need to be versioned
           * Uses the same approach as version-packages.js but tracks sequential versions
           */
          function determineVersionBumps(baseCommit) {
            const packageVersions = {};
            const packageCommits = {};
            
            // Initialize all packages with no bump and empty commits array
            PACKAGES.forEach(pkg => {
              packageVersions[pkg] = null;
              packageCommits[pkg] = [];
            });
            
            // Determine if this is a PR merge (we're simulating it is)
            const isPrMerge = params.mergeBase !== null;
            
            // Get commits since base commit in chronological order (oldest first)
            let gitLogCommand = `git log --reverse ${baseCommit}..HEAD --pretty=format:"%H"`;
            
            // For PR merges, we need to adjust the command to get all commits in the PR
            if (isPrMerge) {
              console.log(`${colors.cyan}PR merge detected, using merge base ${params.mergeBase}${colors.reset}`);
              // Use the provided merge base
              baseCommit = params.mergeBase;
              gitLogCommand = `git log --reverse ${baseCommit}..HEAD --pretty=format:"%H"`;
            }
            
            console.log(`Running command: ${gitLogCommand}`);
            let commitHashes;
            try {
              const output = execSync(gitLogCommand).toString().trim();
              if (output) {
                commitHashes = output.split('\n');
              } else {
                commitHashes = [];
              }
            } catch (error) {
              console.error('Error getting commits:', error.message);
              return { packageVersions, packageCommits };
            }
            
            console.log(`Found ${commitHashes.length} commits since ${baseCommit}`);
            
            // Get current versions for all packages
            const currentVersions = {};
            PACKAGES.forEach(pkg => {
              try {
                const pkgPath = path.join(process.cwd(), pkg, 'package.json');
                if (fs.existsSync(pkgPath)) {
                  const pkgData = JSON.parse(fs.readFileSync(pkgPath, 'utf8'));
                  currentVersions[pkg] = pkgData.version || '0.0.0';
                } else {
                  currentVersions[pkg] = '0.0.0';
                }
              } catch (error) {
                console.error(`Error reading package.json for ${pkg}:`, error.message);
                currentVersions[pkg] = '0.0.0';
              }
            });
            
            // Process each commit in chronological order (oldest first)
            const sequentialVersions = { ...currentVersions };
            
            // Process each commit
            commitHashes.forEach(commitHash => {
              if (!commitHash.trim()) return;
              
              const commitDetails = getCommitDetails(commitHash);
              const message = commitDetails.message;
              
              // Skip merge commits and empty commits
              if (message.startsWith('Merge') || message.trim() === '') {
                return;
              }
              
              console.log(`Analyzing commit: ${message}`);
              
              const scope = extractScope(message);
              const bumpType = commitDetails.bumpType;
              
              console.log(`  Scope: ${scope || 'none'}, Bump type: ${bumpType}`);
              
              // If scope is in excluded list, skip this commit
              if (scope && EXCLUDED_SCOPES.includes(scope)) {
                console.log(`  Skipping excluded scope: ${scope}`);
                return;
              }
              
              // If commit has a scope, apply to the matching package
              if (scope) {
                let matchFound = false;
                
                for (const pkg of PACKAGES) {
                  const pkgName = pkg.split('/').pop();
                  
                  // Check if scope matches package name
                  if (pkgName === scope || scope === 'common') {
                    console.log(`  Matched package: ${pkg}`);
                    matchFound = true;
                    
                    // Calculate the new sequential version for this package
                    const newVersion = incrementVersion(sequentialVersions[pkg], bumpType);
                    
                    // Store the sequential version that this commit would produce
                    commitDetails.exactVersion = newVersion;
                    sequentialVersions[pkg] = newVersion; // Update for next commit
                    
                    // Track this commit for the package
                    packageCommits[pkg].push(commitDetails);
                    
                    // Only break for package-specific scope, not for 'common'
                    if (scope !== 'common') {
                      break;
                    }
                  }
                }
                
                if (!matchFound) {
                  console.log(`  No package match found for scope: ${scope}`);
                }
              } else {
                // No scope in the commit message - apply to ALL packages
                console.log(`  No scope - applying to all packages`);
                
                PACKAGES.forEach(pkg => {
                  // Calculate the new sequential version for this package
                  const newVersion = incrementVersion(sequentialVersions[pkg], bumpType);
                  
                  // Clone the commit details to avoid reference issues across packages
                  const pkgCommitDetails = { ...commitDetails };
                  pkgCommitDetails.exactVersion = newVersion;
                  sequentialVersions[pkg] = newVersion; // Update for next commit
                  
                  // Track this commit for all packages
                  packageCommits[pkg].push(pkgCommitDetails);
                });
              }
            });
            
            // Use the final sequential version as the recommended version bump
            PACKAGES.forEach(pkg => {
              if (packageCommits[pkg].length > 0) {
                // If package has commits, set the packageVersion to the final sequential version
                packageVersions[pkg] = sequentialVersions[pkg];
              }
            });
            
            return { packageVersions, packageCommits, currentVersions, sequentialVersions };
          }

          /**
           * Get current version from package.json
           */
          function getCurrentVersion(pkgPath) {
            try {
              const pkgJsonPath = path.join(process.cwd(), pkgPath, 'package.json');
              if (!fs.existsSync(pkgJsonPath)) {
                console.log(`  Package.json not found for ${pkgPath}`);
                return '0.0.0';
              }
              
              const pkg = JSON.parse(fs.readFileSync(pkgJsonPath, 'utf8'));
              return pkg.version || '0.0.0';
            } catch (error) {
              console.error(`Error reading package.json for ${pkgPath}:`, error.message);
              return '0.0.0';
            }
          }

          /**
           * Update package.json files with new versions (only if not in dry run mode)
           */
          function updatePackageVersions(packageVersions, isDryRun) {
            const updatedPackages = [];
            
            for (const [pkg, newVersion] of Object.entries(packageVersions)) {
              if (!newVersion) continue;
              
              const pkgPath = path.join(process.cwd(), pkg, 'package.json');
              if (!fs.existsSync(pkgPath)) {
                console.log(`Package.json not found for ${pkg}, skipping`);
                continue;
              }
              
              // Read the package.json
              const pkgJson = JSON.parse(fs.readFileSync(pkgPath, 'utf8'));
              const currentVersion = pkgJson.version || '0.0.0';
              
              // Skip if version is already set to the new version
              if (currentVersion === newVersion) {
                console.log(`${pkg} already at version ${newVersion}, skipping`);
                continue;
              }
              
              if (isDryRun) {
                console.log(`${colors.cyan}[DRY RUN]${colors.reset} Would update ${pkg} from ${currentVersion} to ${newVersion}`);
              } else {
                console.log(`${colors.green}Updating${colors.reset} ${pkg} from ${currentVersion} to ${newVersion}`);
                
                // Update the version
                pkgJson.version = newVersion;
                
                // Write the updated package.json
                fs.writeFileSync(pkgPath, JSON.stringify(pkgJson, null, 2) + '\n');
              }
              
              updatedPackages.push({
                name: pkgJson.name || pkg,
                path: pkg,
                version: newVersion,
                previousVersion: currentVersion
              });
            }
            
            return updatedPackages;
          }

          /**
           * Generate Markdown content for version bump details
           */
          function generateBumpDetailsMd(bumpDetails) {
            const timestamp = new Date().toISOString().replace('T', ' at ').substring(0, 19);
            let markdown = `## Version Bump on ${timestamp}${params.dryRun ? ' (SIMULATION)' : ''}\n\n`;
            
            // Generate section for each package
            Object.keys(bumpDetails).forEach(pkg => {
              const details = bumpDetails[pkg];
              if (!details || !details.versionInfo) return;
              
              const { currentVersion, newVersion } = details.versionInfo;
              const commits = details.commits || [];
              
              // Get unique commit types affecting this package
              const commitTypes = [...new Set(commits.map(c => c.type))].filter(Boolean).sort();
              
              markdown += `### ${pkg} → ${newVersion}\n\n`;
              markdown += `- Current version: ${currentVersion}\n`;
              markdown += `- New version: ${newVersion}\n`;
              markdown += `- Affected by commit types: ${commitTypes.join(', ') || 'none'}\n\n`;
              
              // Track each commit with its individual contribution and exact version
              if (commits.length > 0) {
                markdown += '#### Sequential Version Progression\n\n';
                markdown += '| Commit | Message | Bump Type | Exact Version |\n';
                markdown += '|--------|---------|-----------|---------------|\n';
                
                // Show commits in chronological order
                commits.forEach(commit => {
                  const exactVersion = commit.exactVersion || '?';
                  markdown += `| \`${commit.hash}\` | ${commit.message} | **${commit.bumpType}** | **${exactVersion}** |\n`;
                });
                markdown += '\n';
              }
            });
            
            return markdown;
          }

          /**
           * Main function to run version calculation and optionally apply changes
           */
          function runVersioning() {
            console.log(`${colors.bright}${colors.magenta}Version Calculation${params.dryRun ? ' (DRY RUN)' : ' (WILL APPLY CHANGES)'}${colors.reset}`);
            
            // Get current branch and merge base if not provided
            let baseCommit = params.mergeBase;
            if (!baseCommit) {
              const currentBranch = getCurrentBranch();
              console.log(`${colors.blue}Current branch: ${colors.cyan}${currentBranch}${colors.reset}`);
              
              if (currentBranch === 'main') {
                // On main branch, use previous commit as base
                try {
                  baseCommit = execSync('git rev-parse HEAD~1').toString().trim();
                  console.log(`${colors.blue}On main branch, using previous commit as base: ${colors.cyan}${baseCommit}${colors.reset}`);
                } catch (error) {
                  console.error(`${colors.red}Error getting previous commit:${colors.reset}`, error.message);
                  process.exit(1);
                }
              } else {
                baseCommit = getMergeBase(currentBranch);
                console.log(`${colors.blue}Merge base with main: ${colors.cyan}${baseCommit}${colors.reset}`);
              }
            }
            
            console.log(`${colors.blue}Calculating version changes...${colors.reset}\n`);
            
            // Determine version bumps using the actual logic from version-packages.js
            const { packageVersions, packageCommits, currentVersions, sequentialVersions } = determineVersionBumps(baseCommit);
            
            console.log(`\n${colors.bright}${colors.cyan}Version Changes${params.dryRun ? ' that would be applied:' : ' being applied:'}${colors.reset}`);
            console.log(`${colors.yellow}===============================================${colors.reset}`);
            
            // Track how many packages would be updated
            const updatedPackages = updatePackageVersions(packageVersions, params.dryRun);
            let updateCount = updatedPackages.length;
            
            const bumpDetails = {};
            
            // Build the detailed version information for each package
            for (const [pkg, newVersion] of Object.entries(packageVersions)) {
              console.log(`\n${colors.bright}${pkg}:${colors.reset}`);
              
              const currentVersion = currentVersions[pkg] || '0.0.0';
              console.log(`  Current version: ${colors.blue}${currentVersion}${colors.reset}`);
              
              if (newVersion) {
                console.log(`  ${params.dryRun ? 'Would bump to:   ' : 'Bumped to:      '}${colors.green}${newVersion}${colors.reset}`);
                
                // Find the highest bump type used in commits for this package
                let highestBumpType = BUMP_TYPES.PATCH;
                for (const commit of packageCommits[pkg]) {
                  if (commit.bumpType === BUMP_TYPES.MAJOR) {
                    highestBumpType = BUMP_TYPES.MAJOR;
                    break;
                  } else if (commit.bumpType === BUMP_TYPES.MINOR && highestBumpType !== BUMP_TYPES.MAJOR) {
                    highestBumpType = BUMP_TYPES.MINOR;
                  }
                }
                
                // Store details for the bump analysis preview
                bumpDetails[pkg] = {
                  versionInfo: {
                    currentVersion,
                    newVersion,
                    bumpType: highestBumpType
                  },
                  commits: packageCommits[pkg]
                };
              } else {
                console.log(`  ${colors.yellow}No version change ${params.dryRun ? 'would be' : 'was'} applied${colors.reset}`);
              }
            }
            
            console.log(`\n${colors.bright}${colors.green}Version calculation complete!${colors.reset}`);
            
            // Create bump details markdown
            const bumpDetailsMd = generateBumpDetailsMd(bumpDetails);
            
            // In non-dry-run mode, save the bump details to a file
            if (!params.dryRun) {
              try {
                // Create the directory if it doesn't exist
                const bumpDir = path.join(process.cwd(), 'documentation');
                if (!fs.existsSync(bumpDir)) {
                  fs.mkdirSync(bumpDir, { recursive: true });
                }
                
                // Write to version-bumps-analysis.md
                const bumpFilePath = path.join(bumpDir, 'version-bumps-analysis.md');
                
                // Append to existing file or create new file
                let existingContent = '';
                if (fs.existsSync(bumpFilePath)) {
                  existingContent = fs.readFileSync(bumpFilePath, 'utf8');
                }
                
                fs.writeFileSync(bumpFilePath, bumpDetailsMd + '\n\n' + existingContent);
                console.log(`${colors.green}Added version bump details to documentation/version-bumps-analysis.md${colors.reset}`);
                
                // Also create a summary file for the GitHub Action to use
                const summaryPath = path.join(process.cwd(), 'version-summary.md');
                fs.writeFileSync(summaryPath, `# Version Updates\n\n` + 
                  updatedPackages.map(pkg => `- ${pkg.name}: ${pkg.previousVersion} → ${pkg.version}`).join('\n'));
              } catch (error) {
                console.error(`${colors.red}Error writing bump details:${colors.reset}`, error.message);
              }
            }
            
            // For GitHub Actions output in non-dry-run mode, write json output
            if (params.outputJson || !params.dryRun) {
              const output = {
                updatedPackages,
                packagesToTag: updatedPackages.map(pkg => ({
                  name: pkg.name,
                  version: pkg.version,
                  tag: `${pkg.name}@${pkg.version}`
                }))
              };
              
              const outputPath = path.join(process.cwd(), 'version-output.json');
              fs.writeFileSync(outputPath, JSON.stringify(output, null, 2));
              
              console.log(`${colors.green}Wrote version output to version-output.json${colors.reset}`);
            }
            
            // Return result code: 0 if successful and packages would be updated, 1 if no packages would be updated
            return updateCount > 0 ? 0 : 1;
          }

          // Run the versioning process
          try {
            process.exit(runVersioning());
          } catch (error) {
            console.error(`${colors.red}Error:${colors.reset}`, error);
            process.exit(1);
          }
          EOF
          
          # Make the script executable
          chmod +x scripts/version-runner.js
          
          # Add script entry in package.json
          node -e '
          const fs = require("fs");
          const packageJson = JSON.parse(fs.readFileSync("package.json", "utf8"));
          if (!packageJson.scripts) packageJson.scripts = {};
          packageJson.scripts["test-version"] = "node scripts/version-runner.js";
          packageJson.scripts["version-packages"] = "node scripts/version-runner.js --apply";
          fs.writeFileSync("package.json", JSON.stringify(packageJson, null, 2) + "\n");
          console.log("Updated package.json scripts");
          '
          
      # Use the shared version runner script with --apply to actually apply changes
      - name: Calculate and apply version bumps
        id: bump-versions
        run: |
          # Run the version-runner.js script with --apply to actually update versions
          node scripts/version-runner.js --apply --output-json
          
          # Check if the script succeeded and output.json exists
          if [ -f "version-output.json" ]; then
            # Get the updated packages count
            UPDATED_COUNT=$(jq '.updatedPackages | length' version-output.json)
            echo "packages_updated=$UPDATED_COUNT" >> $GITHUB_OUTPUT
            
            # Show what was updated
            echo "Updated $UPDATED_COUNT packages:"
            jq -r '.updatedPackages[] | .name + ": " + .previousVersion + " → " + .version' version-output.json
            
            # Commit the updates to package.json files
            if [ "$UPDATED_COUNT" -gt 0 ]; then
              git config --global user.name "GitHub Actions"
              git config --global user.email "actions@github.com"
              
              # Stage the changed package.json files
              git add "**/package.json"
              
              # Create commit with details
              git commit -m "chore: bump versions [skip ci]" -m "$(cat version-summary.md)"
              
              # Push the changes
              git push origin HEAD
            fi
          else
            echo "packages_updated=0" >> $GITHUB_OUTPUT
            echo "No packages were updated"
          fi
          
      # Create and push tags for the new versions
      - name: Create and push tags
        id: create-tags
        run: |
          echo "Creating and pushing tags..."
          
          # Load the packages that need tagging
          PACKAGES_TO_TAG=$(jq -c '.packagesToTag' version-output.json)
          TAG_COUNT=$(echo "$PACKAGES_TO_TAG" | jq 'length')
          
          # Setup git config
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          
          # Print existing tags for debugging
          echo "Existing tags:"
          git tag -l
          
          # Create directory for release notes
          mkdir -p tmp_release_notes
          TAGS_CREATED=0
          FAILED=0
          
          # Process each package
          echo "$PACKAGES_TO_TAG" | jq -c '.[]' | while read -r package; do
            name=$(echo "$package" | jq -r '.name')
            version=$(echo "$package" | jq -r '.version')
            tag=$(echo "$package" | jq -r '.tag')
            
            echo "Creating tag for $name@$version: $tag"
            
            # Check both possible tag formats
            original_format_tag="$tag"
            transformed_format_tag="${tag/@/}"
            transformed_format_tag="${transformed_format_tag//\//-}"
            
            # Check if tag exists in either format
            if git tag -l "$original_format_tag" | grep -q "$original_format_tag" || \
               git tag -l "$transformed_format_tag" | grep -q "$transformed_format_tag"; then
              echo "Tag already exists in one of the formats, skipping creation"
              continue
            fi
            
            # Create tag with message
            git tag -a "$tag" -m "Release $name v$version"
            
            # Push tag
            if git push origin "$tag"; then
              echo "Successfully pushed tag $tag"
              TAGS_CREATED=$((TAGS_CREATED + 1))
              echo "$tag" >> tags_created.txt
              
              # Create release notes for this package
              local pkg_path=${name#@littlecarlito/}
              local changelog_path="packages/$pkg_path/CHANGELOG.md"
              local release_notes="$name v$version"$'\n\n'
              
              # Add changelog content if available
              if [ -f "$changelog_path" ]; then
                echo "Found changelog at $changelog_path"
                # Extract the relevant section for this version
                local version_content=$(sed -n "/## $version/,/## /p" "$changelog_path" | sed '$ d')
                if [ -n "$version_content" ]; then
                  release_notes+="$version_content"
                else
                  # If no specific version section, add recent commits
                  release_notes+="Changes in this release:"$'\n'
                  release_notes+=$(git log -3 --pretty=format:"* %s (%h)" -- "packages/$pkg_path/")
                fi
              else
                # Use recent commit history for the package
                release_notes+="Changes in this release:"$'\n'
                release_notes+=$(git log -3 --pretty=format:"* %s (%h)" -- "packages/$pkg_path/")
              fi
              
              # Save release notes to a file for later use
              echo "$release_notes" > "tmp_release_notes/${tag}.md"
            else
              echo "Failed to push tag $tag"
              FAILED=$((FAILED + 1))
            fi
          done
          
          # Set outputs
          if [ -f "tags_created.txt" ]; then
            TAGS_CREATED=$(wc -l < tags_created.txt)
            echo "packages_tagged=$TAGS_CREATED" >> $GITHUB_OUTPUT
            echo "tags_created=$(cat tags_created.txt | tr '\n' ',' | sed 's/,$//')" >> $GITHUB_OUTPUT
          else
            echo "packages_tagged=0" >> $GITHUB_OUTPUT
          fi
          
          if [ $FAILED -gt 0 ]; then
            echo "error-message=Failed to create $FAILED tags" >> $GITHUB_OUTPUT
          fi
          
      # Publish packages to npm registry
      - name: Publish packages to npm registry
        if: steps.bump-versions.outputs.packages_updated > 0
        env:
          NODE_AUTH_TOKEN: ${{ secrets.PACKAGE_TOKEN }}
        run: |
          echo "//npm.pkg.github.com/:_authToken=${NODE_AUTH_TOKEN}" > ~/.npmrc
          
          # Publish the packages using pnpm
          pnpm -r publish --filter "@littlecarlito/*" --no-git-checks --access public
          
      # Create GitHub Releases for each tag
      - name: Create GitHub Releases
        id: create-releases
        if: steps.create-tags.outputs.packages_tagged > 0
        env:
          GITHUB_TOKEN: ${{ secrets.VERSION_TOKEN }}
        run: |
          echo "Creating GitHub releases for tags..."
          
          # Read tags that were created
          TAGS_CREATED="${{ steps.create-tags.outputs.tags_created }}"
          
          # Check if tags were created
          if [ -z "$TAGS_CREATED" ]; then
            echo "No tags were created, skipping release creation"
            echo "releases_created=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Create releases for each tag
          RELEASES_CREATED=0
          RELEASES_FAILED=0
          
          # Process each tag
          for tag in $(echo "$TAGS_CREATED" | tr ',' '\n'); do
            echo "Creating release for tag: $tag"
            
            # Check if release notes exist
            if [ -f "tmp_release_notes/${tag}.md" ]; then
              RELEASE_NOTES=$(cat "tmp_release_notes/${tag}.md")
            else
              RELEASE_NOTES="Release $tag"
            fi
            
            # Create the release
            if gh release create "$tag" \
               --title "Release $tag" \
               --notes "$RELEASE_NOTES" \
               --repo "$GITHUB_REPOSITORY"; then
              echo "Successfully created release for $tag"
              RELEASES_CREATED=$((RELEASES_CREATED + 1))
            else
              echo "::error::Failed to create release for $tag"
              RELEASES_FAILED=$((RELEASES_FAILED + 1))
            fi
          done
          
          # Set outputs
          echo "releases_created=$RELEASES_CREATED" >> $GITHUB_OUTPUT
          echo "releases_failed=$RELEASES_FAILED" >> $GITHUB_OUTPUT
          
          if [ $RELEASES_FAILED -gt 0 ]; then
            echo "error-message=Failed to create $RELEASES_FAILED releases" >> $GITHUB_OUTPUT
          fi

  # Build the site for GitHub Pages
  build-site:
    name: Build Site for GitHub Pages
    needs: test
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: main
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 'lts/*'
          registry-url: 'https://npm.pkg.github.com'
          
      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: '8.15.4'
          
      - name: Install dependencies
        run: pnpm install
          
      # Set GITHUB_PAGES environment variable to ensure correct base URL
      - name: Build for GitHub Pages
        run: |
          # First build the blorkpack package explicitly
          pnpm --filter=@littlecarlito/blorkpack build
          # Then build the portfolio with GitHub Pages flag
          GITHUB_PAGES=true pnpm --filter=@littlecarlito/portfolio build
          
      # Ensure _headers file is copied to the dist folder
      - name: Ensure _headers file for GitHub Pages
        run: |
          if [ -f "apps/portfolio/public/_headers" ]; then
            cp apps/portfolio/public/_headers apps/portfolio/dist/
            echo "Copied _headers file to dist folder"
          else
            echo "Warning: _headers file not found"
          fi
          
      # Create a .nojekyll file to disable Jekyll processing
      - name: Add .nojekyll file
        run: touch apps/portfolio/dist/.nojekyll
      
      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: apps/portfolio/dist

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
        with:
          token: ${{ secrets.PACKAGE_TOKEN }} 

  # Report pipeline results (always runs after all jobs)
  report-results:
    name: Report Pipeline Results
    needs: [capture-trigger-info, build, test, version-and-tag, build-site]
    if: always()
    runs-on: ubuntu-latest
    steps:
      # Determine overall workflow result
      - name: Determine workflow result
        id: workflow-result
        run: |
          # Store the outputs from version-and-tag job in a format that avoids context access issues
          TAG_OUTPUTS='${{ toJSON(needs.version-and-tag.outputs) }}'
          RELEASES_FAILED=$(echo "$TAG_OUTPUTS" | jq -r '.["error-message"] // ""')
          
          # Check results of required jobs
          if [[ "${{ needs.build.result }}" == "success" && "${{ needs.test.result }}" == "success" ]]; then
            # Check if version and tag had issues
            if [[ "${{ needs.version-and-tag.result }}" == "success" && -n "$RELEASES_FAILED" && "$RELEASES_FAILED" -gt 0 ]]; then
              echo "result=partial" >> $GITHUB_OUTPUT
              echo "message=Package versioning succeeded but some releases failed to create" >> $GITHUB_OUTPUT
            else
              echo "result=success" >> $GITHUB_OUTPUT
            fi
          else
            echo "result=failure" >> $GITHUB_OUTPUT
          fi
          
          # Get trigger info
          echo "trigger_info=${{ needs.capture-trigger-info.outputs.trigger_info }}" >> $GITHUB_OUTPUT
          echo "trigger_workflow=${{ needs.capture-trigger-info.outputs.trigger_workflow }}" >> $GITHUB_OUTPUT
          echo "trigger_detail=${{ needs.capture-trigger-info.outputs.trigger_detail }}" >> $GITHUB_OUTPUT
          echo "source_branch=${{ needs.capture-trigger-info.outputs.source_branch }}" >> $GITHUB_OUTPUT
          
          # Get detailed error information if version-and-tag failed or had issues
          if [[ "${{ needs.version-and-tag.result }}" == "failure" || (-n "$RELEASES_FAILED" && "$RELEASES_FAILED" -gt 0) ]]; then
            ERROR_MESSAGE="$RELEASES_FAILED"
            
            # Construct detailed error message
            DETAIL_MSG=""
            if [[ -n "$ERROR_MESSAGE" ]]; then
              DETAIL_MSG="error:$ERROR_MESSAGE,"
            fi
            
            echo "error_details=$DETAIL_MSG" >> $GITHUB_OUTPUT
          fi
          
      # Use the new action to report results
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Report pipeline results
        uses: ./.github/actions/report-workflow-results
        with:
          workflow-name: 'Main Pipeline'
          result: ${{ steps.workflow-result.outputs.result }}
          branch: ${{ needs.capture-trigger-info.outputs.source_branch }}
          summary: 'Main Pipeline ${{ steps.workflow-result.outputs.result }}. ${{ needs.capture-trigger-info.outputs.trigger_info }}. Details: ${{ steps.workflow-result.outputs.error_details || needs.capture-trigger-info.outputs.trigger_detail }}. Branch: ${{ needs.capture-trigger-info.outputs.source_branch }}'
          source: 'dispatch'
          discord-webhook-url: ${{ secrets.DISCORD_WEBHOOK_URL }}
          github-token: ${{ secrets.PR_CREATION_TOKEN }} 