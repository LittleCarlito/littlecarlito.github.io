name: Main Pipeline

on:
  push:
    branches:
      - main
    tags:
      - 'v*'
  workflow_dispatch:
    inputs:
      triggered_by:
        description: 'Workflow that triggered this run'
        required: false
        default: 'manual'

# Add concurrency to ensure only one instance runs at a time
concurrency:
  group: github-pages-deploy-${{ github.sha }}
  cancel-in-progress: true

# Define reusable variables
env:
  BUILD_ARTIFACT_NAME: build-artifacts-${{ github.run_id }}
  PACKAGES_ARTIFACT_NAME: package-builds-${{ github.run_id }}
  TRIGGERING_WORKFLOW: ${{ github.event.inputs.triggered_by || 'direct' }}
  
# Note: This workflow handles GitHub Pages deployment directly.
# The separate deploy-pages.yml workflow should be disabled or deleted.
permissions:
  contents: write
  packages: write
  pull-requests: write
  statuses: write
  id-token: write
  actions: write
  issues: write

jobs:
  # Capture information about what triggered this workflow
  capture-trigger-info:
    name: Capture Trigger Info
    runs-on: ubuntu-latest
    outputs:
      trigger_info: ${{ steps.set-trigger-info.outputs.trigger_info }}
      trigger_workflow: ${{ steps.set-trigger-info.outputs.trigger_workflow }}
      trigger_commit: ${{ steps.set-trigger-info.outputs.trigger_commit }}
      trigger_actor: ${{ steps.set-trigger-info.outputs.trigger_actor }}
      trigger_detail: ${{ steps.set-trigger-info.outputs.trigger_detail }}
      source_branch: ${{ steps.set-trigger-info.outputs.source_branch }}
      is_merge_pr: ${{ steps.check-merge-pr.outputs.is_merge_pr }}
      pr_number: ${{ steps.check-merge-pr.outputs.pr_number }}
      source_branch_name: ${{ steps.check-merge-pr.outputs.source_branch_name }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set trigger information
        id: set-trigger-info
        run: |
          # Determine what triggered this workflow
          if [ "${{ github.event_name }}" == "workflow_dispatch" ] && [ "${{ github.event.inputs.triggered_by }}" != "" ]; then
            # Triggered by another workflow
            echo "trigger_workflow=${{ github.event.inputs.triggered_by }}" >> $GITHUB_OUTPUT
            echo "trigger_info=Triggered by ${{ github.event.inputs.triggered_by }} workflow" >> $GITHUB_OUTPUT
            
            # Extract source branch or command from commit message
            LAST_COMMIT=$(git log -1 --pretty=%B)
            
            if [[ "${{ github.event.inputs.triggered_by }}" == "push-create-pr" ]]; then
              # Extract PR number and branch from commit message
              PR_NUM=$(echo "$LAST_COMMIT" | grep -oP "Merge PR #\K\d+")
              SOURCE_BRANCH=$(echo "$LAST_COMMIT" | grep -oP "from \K[^ \n]+")
              echo "trigger_detail=PR #${PR_NUM:-unknown} from branch ${SOURCE_BRANCH:-unknown}" >> $GITHUB_OUTPUT
              echo "source_branch=${SOURCE_BRANCH:-unknown}" >> $GITHUB_OUTPUT
            else
              echo "trigger_detail=From ${{ github.event.inputs.triggered_by }}" >> $GITHUB_OUTPUT
              echo "source_branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT
            fi
            
          elif [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            # Manual trigger
            echo "trigger_workflow=manual" >> $GITHUB_OUTPUT
            echo "trigger_info=Manually triggered by ${{ github.actor }}" >> $GITHUB_OUTPUT
            echo "trigger_detail=Manual workflow dispatch" >> $GITHUB_OUTPUT
            echo "source_branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT
            
          elif [ "${{ github.event_name }}" == "push" ] && [[ "${{ github.ref }}" == refs/tags/* ]]; then
            # Tag push
            echo "trigger_workflow=tag_push" >> $GITHUB_OUTPUT
            echo "trigger_info=Triggered by tag push to ${{ github.ref_name }}" >> $GITHUB_OUTPUT
            echo "trigger_detail=Tag: ${{ github.ref_name }}" >> $GITHUB_OUTPUT
            echo "source_branch=tag:${{ github.ref_name }}" >> $GITHUB_OUTPUT
            
          else
            # Direct push to main
            echo "trigger_workflow=direct_push" >> $GITHUB_OUTPUT
            echo "trigger_info=Triggered by push to ${{ github.ref_name }}" >> $GITHUB_OUTPUT
            
            # Extract commit message details
            COMMIT_MSG=$(git log -1 --pretty=%B)
            COMMIT_TITLE=$(echo "$COMMIT_MSG" | head -n 1)
            echo "trigger_detail=Direct commit: ${COMMIT_TITLE}" >> $GITHUB_OUTPUT
            echo "source_branch=${{ github.ref_name }}" >> $GITHUB_OUTPUT
          fi
          
          # Set commit and actor info
          echo "trigger_commit=${{ github.sha }}" >> $GITHUB_OUTPUT
          echo "trigger_actor=${{ github.actor }}" >> $GITHUB_OUTPUT
          
          # Print debug info
          echo "Workflow triggered by: ${{ github.event_name }}"
          echo "Actor: ${{ github.actor }}"
          echo "Ref: ${{ github.ref }}"
          echo "SHA: ${{ github.sha }}"
      
      - name: Check if this is a PR merge
        id: check-merge-pr
        run: |
          # Get the last commit message
          COMMIT_MSG=$(git log -1 --pretty=%B)
          
          # Check if this is a merge commit from a PR
          if [[ "$COMMIT_MSG" =~ ^Merge\ pull\ request\ #([0-9]+)\ from\ ([^ ]+) ]]; then
            PR_NUM="${BASH_REMATCH[1]}"
            SOURCE_BRANCH="${BASH_REMATCH[2]}"
            echo "This is a PR merge: PR #$PR_NUM from $SOURCE_BRANCH"
            echo "is_merge_pr=true" >> $GITHUB_OUTPUT
            echo "pr_number=$PR_NUM" >> $GITHUB_OUTPUT
            echo "source_branch_name=$SOURCE_BRANCH" >> $GITHUB_OUTPUT
            
            # Get all commits that were in this PR
            echo "Fetching PR commits..."
            MERGE_BASE=$(git merge-base HEAD^ HEAD)
            echo "Merge base: $MERGE_BASE"
            
            # Print all commits in this merge for debugging
            echo "Commits in this PR merge:"
            git log --pretty=format:"%h %s" $MERGE_BASE..HEAD^ | cat
          else
            echo "Not a PR merge"
            echo "is_merge_pr=false" >> $GITHUB_OUTPUT
          fi

  build:
    name: Build
    needs: capture-trigger-info
    runs-on: ubuntu-latest
    outputs:
      build_artifact_name: ${{ env.BUILD_ARTIFACT_NAME }}
      trigger_info: ${{ needs.capture-trigger-info.outputs.trigger_info }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
          
      - name: Debug environment
        run: |
          echo "Debugging environment before build..."
          echo "Node version: $(node -v)"
          echo "NPM version: $(npm -v)"
          command -v pnpm && echo "pnpm version: $(pnpm -v)" || echo "pnpm not found"
          echo "Current directory: $(pwd)"
          echo "Directory contents:"
          ls -la
          echo "Checking for package.json:"
          cat package.json | grep -E 'name|scripts|build'
          echo "Installing dependencies explicitly:"
          npm install -g pnpm
          pnpm install
          echo "Environment debug complete"
          
      # Update .npmrc files to not require NODE_AUTH_TOKEN
      - name: Update .npmrc files
        run: |
          chmod +x .github/scripts/maintenance/update-npmrc.js
          node .github/scripts/maintenance/update-npmrc.js
          
      - name: Build packages
        uses: ./.github/actions/build-and-test
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          build-command: 'pnpm run build'
          test-command: 'echo "Tests will run in separate job"'
          artifact-name: ${{ env.BUILD_ARTIFACT_NAME }}
        
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BUILD_ARTIFACT_NAME }}
          path: packages
          if-no-files-found: error
          
      - name: Validate build artifacts
        run: |
          echo "Validating build artifacts..."
          # Check for dist directories
          DIST_DIRS=$(find packages -name "dist" -type d | wc -l)
          if [ "$DIST_DIRS" -eq 0 ]; then
            echo "::error::No dist directories found in packages!"
            exit 1
          fi
          echo "Found $DIST_DIRS dist directories"
          
          # List all dist directories to verify they exist and contain files
          find packages -name "dist" -type d -exec ls -la {} \;
          
          # Count files to ensure we have artifacts
          FILE_COUNT=$(find packages -name "dist" -type d -exec find {} -type f \; | wc -l)
          echo "Found $FILE_COUNT files in artifact directories"
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "::error::No build artifacts found in packages/dist directories!"
            exit 1
          fi
          
          echo "âœ… Artifact validation successful - $FILE_COUNT files in $DIST_DIRS directories"
          
      - name: Display trigger info
        run: echo "This build was ${{ needs.capture-trigger-info.outputs.trigger_info }}"

  test:
    name: Test
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
          
      # Download build artifacts explicitly first
      - name: Download build artifacts
        id: download-artifacts
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.build.outputs.build_artifact_name }}
          path: packages
        env:
          GH_TOKEN: ${{ secrets.PACKAGE_TOKEN }}
          
      # Validate that artifacts were successfully downloaded
      - name: Validate downloaded artifacts
        run: |
          echo "Validating downloaded artifacts..."
          # Check that artifacts were downloaded
          DIST_DIRS=$(find packages -name "dist" -type d | wc -l)
          if [ "$DIST_DIRS" -eq 0 ]; then
            echo "::error::No dist directories found in downloaded artifacts!"
            exit 1
          fi
          
          # Count files to ensure we have artifacts
          FILE_COUNT=$(find packages -name "dist" -type d -exec find {} -type f \; | wc -l)
          echo "Found $FILE_COUNT files in $DIST_DIRS artifact directories"
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "::error::Downloaded artifacts contain no files!"
            exit 1
          fi
          
          echo "âœ… Downloaded artifacts validation successful"
          
      # Replace workflow call with direct use of the action
      - name: Test packages
        uses: ./.github/actions/test-packages
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          artifact-name: ${{ needs.build.outputs.build_artifact_name }}

  version-and-tag:
    name: Version and Tag Packages
    needs: [test, build, capture-trigger-info]
    if: success()
    runs-on: ubuntu-latest
    permissions:
      contents: write
      packages: write
    outputs:
      tagged: ${{ steps.create-tags.outputs.tagged }}
      skipped: ${{ steps.create-tags.outputs.skipped }}
      error-message: ${{ steps.create-tags.outputs.error-message }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.VERSION_TOKEN }}
          
      # Download build artifacts
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.build.outputs.build_artifact_name }}
          path: packages
        env:
          GH_TOKEN: ${{ secrets.VERSION_TOKEN }}
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 'lts/*'
          registry-url: 'https://npm.pkg.github.com'
          
      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: '8.15.4'
          
      - name: Install dependencies
        run: pnpm install
        
      # Special handling for PR merges to examine all commits
      - name: Prepare for PR merge versioning
        if: needs.capture-trigger-info.outputs.is_merge_pr == 'true'
        run: |
          echo "This is a PR merge: #${{ needs.capture-trigger-info.outputs.pr_number }} from ${{ needs.capture-trigger-info.outputs.source_branch_name }}"
          
          # Find the merge base to get all commits in the PR
          MERGE_BASE=$(git merge-base HEAD^ HEAD)
          echo "Merge base: $MERGE_BASE"
          
          # Get all commits in the PR and write to a file for debugging
          git log --pretty=format:"%h %s" $MERGE_BASE..HEAD^ > pr_commits.txt
          echo "PR commits:"
          cat pr_commits.txt
          
          # Store the merge base for versioning script to use
          echo "MERGE_BASE=$MERGE_BASE" >> $GITHUB_ENV
          
      # Perform dry run of versioning to check if new tags are needed
      - name: Dry run versioning
        id: dry-run
        run: |
          echo "Running version dry run..."
          # Create script to perform dry run versioning
          cat << 'EOF' > version-dry-run.js
          // Simple script to determine if versions need updating
          import { execSync } from 'child_process';
          import fs from 'fs';
          import path from 'path';
          
          // Find all package.json files
          const packagesDir = './packages';
          const packages = [];
          
          // Recursive function to find all package.json files
          function findPackageJson(dir) {
            const files = fs.readdirSync(dir);
            
            for (const file of files) {
              const fullPath = path.join(dir, file);
              const stat = fs.statSync(fullPath);
              
              if (stat.isDirectory()) {
                findPackageJson(fullPath);
              } else if (file === 'package.json') {
                packages.push(dir);
              }
            }
          }
          
          findPackageJson(packagesDir);
          
          let needsVersioning = false;
          const packagesToVersion = [];
          
          // Check each package for version updates
          for (const packageDir of packages) {
            const packageJsonPath = path.join(packageDir, 'package.json');
            const packageJson = JSON.parse(fs.readFileSync(packageJsonPath, 'utf8'));
            
            if (!packageJson.name || !packageJson.version) continue;
            
            // Check if a git tag exists for this version
            const tagName = `${packageJson.name.replace('@', '').replace('/', '-')}@${packageJson.version}`;
            
            try {
              execSync(`git tag -l "${tagName}"`, { stdio: 'pipe' });
              const tagExists = execSync(`git tag -l "${tagName}"`).toString().trim() === tagName;
              
              if (!tagExists) {
                console.log(`Package ${packageJson.name} at version ${packageJson.version} has no tag`);
                needsVersioning = true;
                packagesToVersion.push({
                  name: packageJson.name,
                  version: packageJson.version,
                  tag: tagName
                });
              }
            } catch (error) {
              console.error(`Error checking tag for ${packageJson.name}:`, error.message);
            }
          }
          
          // Output results
          console.log(`Found ${packagesToVersion.length} packages that need tagging`);
          
          if (packagesToVersion.length > 0) {
            console.log('NEEDS_VERSIONING=true');
            fs.writeFileSync('packages-to-version.json', JSON.stringify(packagesToVersion, null, 2));
          } else {
            console.log('NEEDS_VERSIONING=false');
          }
          
          process.exit(packagesToVersion.length > 0 ? 0 : 1);
          EOF
          
          # Run the dry run script
          if node version-dry-run.js; then
            echo "needs_versioning=true" >> $GITHUB_OUTPUT
            echo "Packages need versioning"
            cat packages-to-version.json
          else
            echo "needs_versioning=false" >> $GITHUB_OUTPUT
            echo "All packages are properly tagged"
          fi
          
      # Create tags and push them to GitHub
      - name: Create and push tags
        id: create-tags
        if: steps.dry-run.outputs.needs_versioning == 'true'
        env:
          NODE_AUTH_TOKEN: ${{ secrets.PACKAGE_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.VERSION_TOKEN }}
        run: |
          echo "Creating and pushing tags..."
          
          # Load the packages that need tagging
          PACKAGES_TO_VERSION=$(cat packages-to-version.json)
          
          # Setup git config
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          
          # Function to create and push a tag
          create_tag() {
            local package_name=$1
            local version=$2
            local tag_name=$3
            
            echo "Creating tag for $package_name@$version: $tag_name"
            
            # Create tag with message
            git tag -a "$tag_name" -m "Release $package_name v$version"
            
            # Push tag
            if git push origin "$tag_name"; then
              echo "Successfully pushed tag $tag_name"
              return 0
            else
              echo "Failed to push tag $tag_name"
              return 1
            fi
          }
          
          # Process each package
          TAGGED=0
          FAILED=0
          
          # Parse the JSON and iterate through packages
          echo "$PACKAGES_TO_VERSION" | jq -c '.[]' | while read -r package; do
            name=$(echo "$package" | jq -r '.name')
            version=$(echo "$package" | jq -r '.version')
            tag=$(echo "$package" | jq -r '.tag')
            
            if create_tag "$name" "$version" "$tag"; then
              TAGGED=$((TAGGED + 1))
            else
              FAILED=$((FAILED + 1))
              echo "::error::Failed to create tag for $name@$version"
            fi
          done
          
          # Publish packages to npm registry if needed
          echo "//npm.pkg.github.com/:_authToken=${NODE_AUTH_TOKEN}" > ~/.npmrc
          
          # Publish the packages using pnpm
          pnpm -r publish --no-git-checks --access public
          
          # Set outputs
          echo "tagged=$TAGGED" >> $GITHUB_OUTPUT
          
          if [ $FAILED -gt 0 ]; then
            echo "error-message=Failed to create $FAILED tags" >> $GITHUB_OUTPUT
          fi
          
          if [ $TAGGED -eq 0 ]; then
            echo "skipped=true" >> $GITHUB_OUTPUT
          else
            echo "skipped=false" >> $GITHUB_OUTPUT
          fi

  # Build the site for GitHub Pages
  build-site:
    name: Build Site for GitHub Pages
    needs: test
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: main
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 'lts/*'
          registry-url: 'https://npm.pkg.github.com'
          
      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: '8.15.4'
          
      - name: Install dependencies
        run: pnpm install
          
      # Set GITHUB_PAGES environment variable to ensure correct base URL
      - name: Build for GitHub Pages
        run: |
          # First build the blorkpack package explicitly
          pnpm --filter=@littlecarlito/blorkpack build
          # Then build the portfolio with GitHub Pages flag
          GITHUB_PAGES=true pnpm --filter=@littlecarlito/portfolio build
          
      # Ensure _headers file is copied to the dist folder
      - name: Ensure _headers file for GitHub Pages
        run: |
          if [ -f "apps/portfolio/public/_headers" ]; then
            cp apps/portfolio/public/_headers apps/portfolio/dist/
            echo "Copied _headers file to dist folder"
          else
            echo "Warning: _headers file not found"
          fi
          
      # Create a .nojekyll file to disable Jekyll processing
      - name: Add .nojekyll file
        run: touch apps/portfolio/dist/.nojekyll
      
      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: apps/portfolio/dist

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
        with:
          token: ${{ secrets.PACKAGE_TOKEN }} 

  # Report pipeline results (always runs after all jobs)
  report-results:
    name: Report Pipeline Results
    needs: [capture-trigger-info, build, test, version-and-tag, build-site]
    if: always()
    runs-on: ubuntu-latest
    steps:
      # Determine overall workflow result
      - name: Determine workflow result
        id: workflow-result
        run: |
          # Store the outputs from version-and-tag job in a format that avoids context access issues
          TAG_OUTPUTS='${{ toJSON(needs.version-and-tag.outputs) }}'
          RELEASES_FAILED=$(echo "$TAG_OUTPUTS" | jq -r '.["error-message"] // ""')
          
          # Check results of required jobs
          if [[ "${{ needs.build.result }}" == "success" && "${{ needs.test.result }}" == "success" ]]; then
            # Check if version and tag had issues
            if [[ "${{ needs.version-and-tag.result }}" == "success" && -n "$RELEASES_FAILED" && "$RELEASES_FAILED" -gt 0 ]]; then
              echo "result=partial" >> $GITHUB_OUTPUT
              echo "message=Package versioning succeeded but some releases failed to create" >> $GITHUB_OUTPUT
            else
              echo "result=success" >> $GITHUB_OUTPUT
            fi
          else
            echo "result=failure" >> $GITHUB_OUTPUT
          fi
          
          # Get trigger info
          echo "trigger_info=${{ needs.capture-trigger-info.outputs.trigger_info }}" >> $GITHUB_OUTPUT
          echo "trigger_workflow=${{ needs.capture-trigger-info.outputs.trigger_workflow }}" >> $GITHUB_OUTPUT
          echo "trigger_detail=${{ needs.capture-trigger-info.outputs.trigger_detail }}" >> $GITHUB_OUTPUT
          echo "source_branch=${{ needs.capture-trigger-info.outputs.source_branch }}" >> $GITHUB_OUTPUT
          
          # Get detailed error information if version-and-tag failed or had issues
          if [[ "${{ needs.version-and-tag.result }}" == "failure" || (-n "$RELEASES_FAILED" && "$RELEASES_FAILED" -gt 0) ]]; then
            ERROR_MESSAGE="$RELEASES_FAILED"
            
            # Construct detailed error message
            DETAIL_MSG=""
            if [[ -n "$ERROR_MESSAGE" ]]; then
              DETAIL_MSG="error:$ERROR_MESSAGE,"
            fi
            
            echo "error_details=$DETAIL_MSG" >> $GITHUB_OUTPUT
          fi
          
      # Use the new action to report results
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Report pipeline results
        uses: ./.github/actions/report-workflow-results
        with:
          workflow-name: 'Main Pipeline'
          result: ${{ steps.workflow-result.outputs.result }}
          branch: ${{ needs.capture-trigger-info.outputs.source_branch }}
          summary: 'Main Pipeline ${{ steps.workflow-result.outputs.result }}. ${{ needs.capture-trigger-info.outputs.trigger_info }}. Details: ${{ steps.workflow-result.outputs.error_details || needs.capture-trigger-info.outputs.trigger_detail }}. Branch: ${{ needs.capture-trigger-info.outputs.source_branch }}'
          source: 'dispatch'
          discord-webhook-url: ${{ secrets.DISCORD_WEBHOOK_URL }}
          github-token: ${{ secrets.PR_CREATION_TOKEN }} 